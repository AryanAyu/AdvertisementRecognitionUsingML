{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ayush/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length:  33117\n",
      "Dataset Shape:  (33117, 205)\n",
      "(23181, 204)\n",
      "(23181,)\n",
      "Time taken to train using gini: 1.246314\n",
      "Time taken to train using entropy: 1.6735539999999993\n",
      "Results Using Gini Index:\n",
      "Time taken to test using gini: 0.01654100000000014\n",
      "Confusion Matrix:\n",
      " [[2528  969]\n",
      " [ 390 6049]]\n",
      "Accuracy :\n",
      " 86.32246376811594\n",
      "Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.87      0.72      0.79      3497\n",
      "        1.0       0.86      0.94      0.90      6439\n",
      "\n",
      "avg / total       0.86      0.86      0.86      9936\n",
      "\n",
      "Results Using Entropy:\n",
      "Time taken to test using entropy: 0.006837999999998345\n",
      "Confusion Matrix:\n",
      " [[2251 1246]\n",
      " [ 327 6112]]\n",
      "Accuracy :\n",
      " 84.16867954911433\n",
      "Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.87      0.64      0.74      3497\n",
      "        1.0       0.83      0.95      0.89      6439\n",
      "\n",
      "avg / total       0.85      0.84      0.83      9936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing the required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.mlab import PCA\n",
    "\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def cal_accuracy(y_test, y_pred):\n",
    "     \n",
    "    print(\"Confusion Matrix:\\n\",\n",
    "        confusion_matrix(y_test, y_pred))\n",
    "     \n",
    "    print (\"Accuracy :\\n\",\n",
    "    accuracy_score(y_test,y_pred)*100)\n",
    "     \n",
    "    print(\"Report :\\n\",\n",
    "    classification_report(y_test, y_pred))\n",
    " \n",
    "data = pd.read_csv('CNNIBN_Cleaned.csv')\n",
    "print (\"Dataset Length: \", len(data))\n",
    "print (\"Dataset Shape: \", data.shape)\n",
    "X = data.values[:, 0:204]\n",
    "y = data.values[:, 204]\n",
    " \n",
    "# Spliting the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 100)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Creating the classifier object\n",
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\",random_state = 100,max_depth=3, min_samples_leaf=5)\n",
    "# Performing training\n",
    "start = time.clock()\n",
    "clf_gini.fit(X_train, y_train)\n",
    "print(\"Time taken to train using gini:\",time.clock()-start)    \n",
    "# Decision tree with entropy\n",
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100,max_depth = 3, min_samples_leaf = 5)\n",
    "# Performing training\n",
    "start = time.clock()\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "print(\"Time taken to train using entropy:\",time.clock()-start)   \n",
    "     \n",
    "# Operational Phase\n",
    "\n",
    "print(\"Results Using Gini Index:\")     \n",
    "# Prediction using gini\n",
    "start = time.clock()\n",
    "y_pred_gini = clf_gini.predict(X_test)\n",
    "print(\"Time taken to test using gini:\",time.clock()-start)    \n",
    "cal_accuracy(y_test, y_pred_gini)\n",
    "     \n",
    "print(\"Results Using Entropy:\")\n",
    "# Prediction using entropy\n",
    "start = time.clock()\n",
    "y_pred_entropy = clf_entropy.predict(X_test)\n",
    "print(\"Time taken to test using entropy:\",time.clock()-start)    \n",
    "cal_accuracy(y_test, y_pred_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23181, 204)\n",
      "(23181,)\n",
      "Time taken to train using svm: 671.679845\n",
      "Time taken to test using svm: 15.529901999999993\n",
      "Confusion Matrix:\n",
      " [[2567  930]\n",
      " [ 456 5983]]\n",
      "Accuracy :\n",
      " 86.05072463768117\n",
      "Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.85      0.73      0.79      3497\n",
      "        1.0       0.87      0.93      0.90      6439\n",
      "\n",
      "avg / total       0.86      0.86      0.86      9936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM Algorithm\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "start = time.clock()\n",
    "svm_model_linear.fit(X_train, y_train)\n",
    "print(\"Time taken to train using svm:\",time.clock()-start)    \n",
    "start = time.clock()\n",
    "svm_predictions = svm_model_linear.predict(X_test)\n",
    "print(\"Time taken to test using svm:\",time.clock()-start)    \n",
    "cal_accuracy(y_test, svm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 0s - loss: 0.6735 - acc: 0.6558\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6515 - acc: 0.6550\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6457 - acc: 0.6550\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6438 - acc: 0.6550\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6427 - acc: 0.6550\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6410 - acc: 0.6550\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6372 - acc: 0.6550\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6268 - acc: 0.6550\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.5975 - acc: 0.6550\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.5433 - acc: 0.6550\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.4858 - acc: 0.6550\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.4375 - acc: 0.6715\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.3949 - acc: 0.8843\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.3592 - acc: 0.8930\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.3322 - acc: 0.8993\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.3109 - acc: 0.9045\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.2939 - acc: 0.9090\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.2800 - acc: 0.9118\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.2687 - acc: 0.9137\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.2593 - acc: 0.9149\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.2512 - acc: 0.9171\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.2445 - acc: 0.9187\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.2388 - acc: 0.9201\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.2342 - acc: 0.9206\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.2301 - acc: 0.9213\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.2265 - acc: 0.9222\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.2238 - acc: 0.9229\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.2211 - acc: 0.9239\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.2187 - acc: 0.9244\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.2167 - acc: 0.9245\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.2149 - acc: 0.9252\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.2136 - acc: 0.9256\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.2117 - acc: 0.9261\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.2107 - acc: 0.9255\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.2093 - acc: 0.9262\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.2085 - acc: 0.9264\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.2073 - acc: 0.9270\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.2061 - acc: 0.9268\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.2056 - acc: 0.9273\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.2050 - acc: 0.9275\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.2041 - acc: 0.9273\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.2030 - acc: 0.9270\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.2026 - acc: 0.9279\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.2023 - acc: 0.9282\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.2011 - acc: 0.9279\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.2009 - acc: 0.9284\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.2005 - acc: 0.9286\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.2000 - acc: 0.9287\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.1991 - acc: 0.9285\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.1987 - acc: 0.9289\n",
      "Epoch 1/50\n",
      " - 0s - loss: 0.6738 - acc: 0.6485\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6519 - acc: 0.6550\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6461 - acc: 0.6550\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6444 - acc: 0.6550\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6437 - acc: 0.6550\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6430 - acc: 0.6550\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6416 - acc: 0.6550\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6376 - acc: 0.6550\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6219 - acc: 0.6552\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.5514 - acc: 0.7604\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.4434 - acc: 0.8611\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.3836 - acc: 0.8832\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.3476 - acc: 0.8930\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.3227 - acc: 0.8996\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.3048 - acc: 0.9048\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.2918 - acc: 0.9075\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.2820 - acc: 0.9102\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.2743 - acc: 0.9119\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.2679 - acc: 0.9138\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.2622 - acc: 0.9154\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.2573 - acc: 0.9162\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.2530 - acc: 0.9178\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.2494 - acc: 0.9182\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.2462 - acc: 0.9194\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.2437 - acc: 0.9201\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.2410 - acc: 0.9209\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.2391 - acc: 0.9209\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.2370 - acc: 0.9216\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.2356 - acc: 0.9215\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.2338 - acc: 0.9216\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.2325 - acc: 0.9218\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.2311 - acc: 0.9224\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.2301 - acc: 0.9227\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.2296 - acc: 0.9221\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.2285 - acc: 0.9236\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.2272 - acc: 0.9233\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.2264 - acc: 0.9230\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.2259 - acc: 0.9239\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.2251 - acc: 0.9238\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.2245 - acc: 0.9236\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.2239 - acc: 0.9241\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.2236 - acc: 0.9238\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.2231 - acc: 0.9232\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.2225 - acc: 0.9236\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.2223 - acc: 0.9236\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.2215 - acc: 0.9238\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.2210 - acc: 0.9249\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.2205 - acc: 0.9238\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.2200 - acc: 0.9241\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.2197 - acc: 0.9242\n",
      "Epoch 1/50\n",
      " - 0s - loss: 0.6738 - acc: 0.6490\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6520 - acc: 0.6550\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6463 - acc: 0.6550\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6447 - acc: 0.6550\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6442 - acc: 0.6550\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6440 - acc: 0.6550\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6438 - acc: 0.6550\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6435 - acc: 0.6550\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6429 - acc: 0.6550\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6416 - acc: 0.6550\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6377 - acc: 0.6550\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6219 - acc: 0.6551\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.5468 - acc: 0.7617\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.4331 - acc: 0.8719\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.3763 - acc: 0.8877\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.3430 - acc: 0.8951\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.3205 - acc: 0.9014\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.3040 - acc: 0.9045\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.2919 - acc: 0.9065\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.2823 - acc: 0.9096\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.2742 - acc: 0.9112\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.2673 - acc: 0.9131\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.2615 - acc: 0.9150\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.2562 - acc: 0.9153\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.2516 - acc: 0.9164\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.2475 - acc: 0.9184\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.2439 - acc: 0.9198\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.2408 - acc: 0.9200\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.2382 - acc: 0.9212\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.2357 - acc: 0.9214\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.2340 - acc: 0.9216\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.2322 - acc: 0.9225\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.2309 - acc: 0.9221\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.2294 - acc: 0.9236\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.2282 - acc: 0.9225\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.2276 - acc: 0.9238\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.2264 - acc: 0.9239\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.2252 - acc: 0.9242\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.2247 - acc: 0.9238\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.2239 - acc: 0.9236\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.2233 - acc: 0.9245\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.2223 - acc: 0.9239\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.2219 - acc: 0.9236\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.2215 - acc: 0.9241\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.2207 - acc: 0.9243\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.2205 - acc: 0.9247\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.2204 - acc: 0.9245\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.2194 - acc: 0.9241\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.2190 - acc: 0.9252\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.2186 - acc: 0.9245\n",
      "Epoch 1/50\n",
      " - 0s - loss: 0.6738 - acc: 0.6526\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6519 - acc: 0.6551\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6461 - acc: 0.6551\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6446 - acc: 0.6551\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6441 - acc: 0.6551\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6438 - acc: 0.6551\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6435 - acc: 0.6551\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6431 - acc: 0.6551\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6424 - acc: 0.6551\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6411 - acc: 0.6551\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6382 - acc: 0.6551\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6313 - acc: 0.6551\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6129 - acc: 0.6551\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.5701 - acc: 0.6551\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.5100 - acc: 0.6551\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.4518 - acc: 0.6551\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.4044 - acc: 0.8470\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.3673 - acc: 0.8936\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.3386 - acc: 0.9020\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.3160 - acc: 0.9059\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.2972 - acc: 0.9083\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.2819 - acc: 0.9107\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.2692 - acc: 0.9130\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.2589 - acc: 0.9147\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.2504 - acc: 0.9158\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2434 - acc: 0.9169\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.2374 - acc: 0.9184\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.2327 - acc: 0.9188\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.2286 - acc: 0.9195\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.2252 - acc: 0.9162\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.2222 - acc: 0.9171\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.2195 - acc: 0.9183\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.2175 - acc: 0.9176\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.2152 - acc: 0.9185\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.2135 - acc: 0.9190\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.2119 - acc: 0.9193\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.2104 - acc: 0.9197\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.2088 - acc: 0.9197\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.2077 - acc: 0.9201\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.2064 - acc: 0.9209\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.2056 - acc: 0.9222\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.2046 - acc: 0.9252\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.2035 - acc: 0.9255\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.2024 - acc: 0.9262\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.2016 - acc: 0.9259\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.2008 - acc: 0.9265\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.2001 - acc: 0.9269\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.1994 - acc: 0.9267\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.1986 - acc: 0.9265\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.1983 - acc: 0.9268\n",
      "Epoch 1/50\n",
      " - 0s - loss: 0.6739 - acc: 0.6490\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6520 - acc: 0.6550\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6464 - acc: 0.6550\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6448 - acc: 0.6550\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6444 - acc: 0.6550\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6442 - acc: 0.6550\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6442 - acc: 0.6550\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6441 - acc: 0.6550\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6441 - acc: 0.6550\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6439 - acc: 0.6550\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6438 - acc: 0.6550\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6436 - acc: 0.6550\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6431 - acc: 0.6550\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6423 - acc: 0.6550\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6406 - acc: 0.6550\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6363 - acc: 0.6550\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6245 - acc: 0.6550\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.5930 - acc: 0.6550\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.5414 - acc: 0.6550\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.4894 - acc: 0.6550\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.4442 - acc: 0.6816\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.4056 - acc: 0.8688\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.3723 - acc: 0.8865\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.3460 - acc: 0.8869\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.3248 - acc: 0.8901\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.3066 - acc: 0.8975\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.2909 - acc: 0.9027\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.2772 - acc: 0.9076\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.2660 - acc: 0.9106\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.2568 - acc: 0.9130\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.2493 - acc: 0.9138\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.2431 - acc: 0.9148\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.2378 - acc: 0.9169\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.2335 - acc: 0.9172\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.2303 - acc: 0.9175\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.2269 - acc: 0.9190\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.2240 - acc: 0.9200\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.2221 - acc: 0.9198\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.2200 - acc: 0.9210\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.2183 - acc: 0.9216\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.2163 - acc: 0.9225\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.2154 - acc: 0.9215\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.2140 - acc: 0.9224\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.2129 - acc: 0.9220\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.2115 - acc: 0.9228\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.2103 - acc: 0.9233\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.2100 - acc: 0.9222\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.2091 - acc: 0.9230\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.2077 - acc: 0.9236\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.2070 - acc: 0.9247\n",
      "Time taken for cross validation: 44.230077951225184\n",
      "(33117, 204)\n",
      "(33117,)\n",
      "Baseline: 92.31% (0.47%)\n"
     ]
    }
   ],
   "source": [
    "# baseline model\n",
    "#ANN\n",
    "def create_baseline():\n",
    " # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2, input_dim=204, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(2, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    sgd = SGD(lr=0.01, momentum=0.8, decay=0.0, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "# fix random seed for reproducibility\n",
    "\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=50, batch_size=500, verbose=2)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "start = time.clock()\n",
    "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
    "print(\"Time taken for cross validation:\",time.clock()-start)    \n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(11424, 205)\n",
      "(21693, 205)\n",
      "(22848, 205)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>924</th>\n",
       "      <th>959</th>\n",
       "      <th>1002</th>\n",
       "      <th>1016</th>\n",
       "      <th>1028</th>\n",
       "      <th>1048</th>\n",
       "      <th>1112</th>\n",
       "      <th>4124</th>\n",
       "      <th>4125</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "      <td>22848.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>98.116246</td>\n",
       "      <td>2.910306</td>\n",
       "      <td>1.749344</td>\n",
       "      <td>13.559205</td>\n",
       "      <td>8.865996</td>\n",
       "      <td>0.015107</td>\n",
       "      <td>0.010420</td>\n",
       "      <td>0.106737</td>\n",
       "      <td>0.059480</td>\n",
       "      <td>3596.644097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.023290</td>\n",
       "      <td>0.019954</td>\n",
       "      <td>0.019382</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.499437</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>239.742374</td>\n",
       "      <td>2.190076</td>\n",
       "      <td>1.324933</td>\n",
       "      <td>9.061300</td>\n",
       "      <td>6.786087</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.030565</td>\n",
       "      <td>0.019152</td>\n",
       "      <td>230.354699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043841</td>\n",
       "      <td>0.043708</td>\n",
       "      <td>0.040220</td>\n",
       "      <td>0.044261</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.034942</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.289458</td>\n",
       "      <td>0.288786</td>\n",
       "      <td>1.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.028928</td>\n",
       "      <td>0.007988</td>\n",
       "      <td>0.451168</td>\n",
       "      <td>0.182447</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.011621</td>\n",
       "      <td>0.005959</td>\n",
       "      <td>1092.421021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.226711</td>\n",
       "      <td>0.839096</td>\n",
       "      <td>6.727920</td>\n",
       "      <td>3.805882</td>\n",
       "      <td>0.012609</td>\n",
       "      <td>0.008563</td>\n",
       "      <td>0.087490</td>\n",
       "      <td>0.047077</td>\n",
       "      <td>3411.841247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.246764</td>\n",
       "      <td>0.249865</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.326412</td>\n",
       "      <td>1.512451</td>\n",
       "      <td>11.388556</td>\n",
       "      <td>7.049645</td>\n",
       "      <td>0.015369</td>\n",
       "      <td>0.010618</td>\n",
       "      <td>0.104871</td>\n",
       "      <td>0.056257</td>\n",
       "      <td>3627.747070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502497</td>\n",
       "      <td>0.499007</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>4.103518</td>\n",
       "      <td>2.292123</td>\n",
       "      <td>18.697786</td>\n",
       "      <td>12.250341</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.012488</td>\n",
       "      <td>0.124118</td>\n",
       "      <td>0.067812</td>\n",
       "      <td>3782.408631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.027480</td>\n",
       "      <td>0.021536</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751876</td>\n",
       "      <td>0.748735</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16201.000000</td>\n",
       "      <td>14.958882</td>\n",
       "      <td>37.363274</td>\n",
       "      <td>64.107498</td>\n",
       "      <td>45.679489</td>\n",
       "      <td>0.032740</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>0.386957</td>\n",
       "      <td>0.205533</td>\n",
       "      <td>3985.526123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.577586</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1             2             3             4             5  \\\n",
       "count  22848.000000  22848.000000  22848.000000  22848.000000  22848.000000   \n",
       "mean      98.116246      2.910306      1.749344     13.559205      8.865996   \n",
       "std      239.742374      2.190076      1.324933      9.061300      6.786087   \n",
       "min       25.000000      0.028928      0.007988      0.451168      0.182447   \n",
       "25%       30.000000      1.226711      0.839096      6.727920      3.805882   \n",
       "50%       50.000000      2.326412      1.512451     11.388556      7.049645   \n",
       "75%       98.000000      4.103518      2.292123     18.697786     12.250341   \n",
       "max    16201.000000     14.958882     37.363274     64.107498     45.679489   \n",
       "\n",
       "                  6             7             8             9            10  \\\n",
       "count  22848.000000  22848.000000  22848.000000  22848.000000  22848.000000   \n",
       "mean       0.015107      0.010420      0.106737      0.059480   3596.644097   \n",
       "std        0.004366      0.002886      0.030565      0.019152    230.354699   \n",
       "min        0.000035      0.000016      0.011621      0.005959   1092.421021   \n",
       "25%        0.012609      0.008563      0.087490      0.047077   3411.841247   \n",
       "50%        0.015369      0.010618      0.104871      0.056257   3627.747070   \n",
       "75%        0.017900      0.012488      0.124118      0.067812   3782.408631   \n",
       "max        0.032740      0.020036      0.386957      0.205533   3985.526123   \n",
       "\n",
       "           ...                924           959          1002          1016  \\\n",
       "count      ...       22848.000000  22848.000000  22848.000000  22848.000000   \n",
       "mean       ...           0.019100      0.023290      0.019954      0.019382   \n",
       "std        ...           0.043841      0.043708      0.040220      0.044261   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.000000      0.005449      0.000000      0.000000   \n",
       "75%        ...           0.020000      0.027480      0.021536      0.013158   \n",
       "max        ...           0.762500      0.812500      0.577586      0.621622   \n",
       "\n",
       "               1028          1048          1112          4124          4125  \\\n",
       "count  22848.000000  22848.000000  22848.000000  22848.000000  22848.000000   \n",
       "mean       0.000080      0.018220      0.000574      0.500227      0.499437   \n",
       "std        0.000935      0.034942      0.003405      0.289458      0.288786   \n",
       "min        0.000000      0.000000      0.000000      0.000067      0.000027   \n",
       "25%        0.000000      0.000000      0.000000      0.246764      0.249865   \n",
       "50%        0.000000      0.000000      0.000000      0.502497      0.499007   \n",
       "75%        0.000000      0.023039      0.000000      0.751876      0.748735   \n",
       "max        0.037500      0.530303      0.148148      0.999948      0.999997   \n",
       "\n",
       "              Label  \n",
       "count  22848.000000  \n",
       "mean       0.000000  \n",
       "std        1.000022  \n",
       "min       -1.000000  \n",
       "25%       -1.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 205 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(data))\n",
    "(n,p)=(data[data['Label']==-1],data[data['Label']==1]) # dividing df into two new dfs\n",
    "print(n.shape)\n",
    "print(p.shape)\n",
    "#21693 +ve labels, 11424 -ve labels\n",
    "p = p.iloc[:11424] # slicing\n",
    "data = pd.concat([n,p]) # merging them again, now we have same number of +ve and -ve reviews\n",
    "data=data.sample(frac=1) # shuffling the rows\n",
    "data=data.reset_index(drop=True) # reset index\n",
    "print(data.shape)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train using gini: 1.0106718416031981\n",
      "Time taken to train using gini: 1.4498327244741915\n",
      "(15993, 204)\n",
      "(15993,)\n",
      "Results Using Gini Index:\n",
      "Time taken to test using gini: 0.006311592967932711\n",
      "Confusion Matrix:\n",
      " [[2831  591]\n",
      " [ 438 2995]]\n",
      "Accuracy :\n",
      " 84.989059081\n",
      "Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.87      0.83      0.85      3422\n",
      "        1.0       0.84      0.87      0.85      3433\n",
      "\n",
      "avg / total       0.85      0.85      0.85      6855\n",
      "\n",
      "Results Using Entropy:\n",
      "Time taken to test using entropy: 0.006546965332375976\n",
      "Confusion Matrix:\n",
      " [[3250  172]\n",
      " [ 965 2468]]\n",
      "Accuracy :\n",
      " 83.4135667396\n",
      "Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.77      0.95      0.85      3422\n",
      "        1.0       0.93      0.72      0.81      3433\n",
      "\n",
      "avg / total       0.85      0.83      0.83      6855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data.values[:, 0:204]\n",
    "y = data.values[:, 204]\n",
    " \n",
    "# Spliting the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 100)\n",
    "# Creating the classifier object\n",
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\",random_state = 100,max_depth=3, min_samples_leaf=5)\n",
    "# Performing training\n",
    "start = time.clock()\n",
    "clf_gini.fit(X_train, y_train)\n",
    "print(\"Time taken to train using gini:\",time.clock()-start)    \n",
    "\n",
    "# Decision tree with entropy\n",
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100,max_depth = 3, min_samples_leaf = 5)\n",
    "# Performing training\n",
    "start = time.clock()\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "print(\"Time taken to train using entropy:\",time.clock()-start)    \n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Operational Phase\n",
    "\n",
    "print(\"Results Using Gini Index:\")     \n",
    "# Prediction using gini\n",
    "start = time.clock()\n",
    "y_pred_gini = clf_gini.predict(X_test)\n",
    "print(\"Time taken to test using gini:\",time.clock()-start)    \n",
    "cal_accuracy(y_test, y_pred_gini)\n",
    "     \n",
    "print(\"Results Using Entropy:\")\n",
    "# Prediction using entropy\n",
    "start = time.clock()\n",
    "y_pred_entropy = clf_entropy.predict(X_test)\n",
    "print(\"Time taken to test using entropy:\",time.clock()-start)    \n",
    "cal_accuracy(y_test, y_pred_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15993, 204)\n",
      "(15993,)\n",
      "Time taken to train using svm: 532.5811343678323\n",
      "Time taken to test using svm: 10.336436472168657\n",
      "Confusion Matrix:\n",
      " [[2850  572]\n",
      " [ 442 2991]]\n",
      "Accuracy :\n",
      " 85.2078774617\n",
      "Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.87      0.83      0.85      3422\n",
      "        1.0       0.84      0.87      0.86      3433\n",
      "\n",
      "avg / total       0.85      0.85      0.85      6855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "start = time.clock()\n",
    "svm_model_linear.fit(X_train, y_train)\n",
    "print(\"Time taken to train using svm:\",time.clock()-start)    \n",
    "start = time.clock()\n",
    "svm_predictions = svm_model_linear.predict(X_test)\n",
    "print(\"Time taken to test using svm:\",time.clock()-start)    \n",
    "cal_accuracy(y_test, svm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 1s - loss: 0.6930 - acc: 0.5014\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5307\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5818\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5057\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5553\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6926 - acc: 0.6314\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6924 - acc: 0.6401\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6921 - acc: 0.6068\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6916 - acc: 0.6565\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6906 - acc: 0.6670\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6888 - acc: 0.6804\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6849 - acc: 0.6930\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6758 - acc: 0.7097\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6528 - acc: 0.7305\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6035 - acc: 0.7630\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.5351 - acc: 0.8193\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.4701 - acc: 0.8605\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.4206 - acc: 0.8808\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.3845 - acc: 0.8880\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.3566 - acc: 0.8936\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.3327 - acc: 0.9000\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.3132 - acc: 0.9049\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.2974 - acc: 0.9084\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.2843 - acc: 0.9113\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.2736 - acc: 0.9142\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.2644 - acc: 0.9159\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.2565 - acc: 0.9174\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.2498 - acc: 0.9194\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.2441 - acc: 0.9188\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.2391 - acc: 0.9212\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.2346 - acc: 0.9216\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.2307 - acc: 0.9230\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.2272 - acc: 0.9243\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.2241 - acc: 0.9237\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.2220 - acc: 0.9246\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.2190 - acc: 0.9259\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.2170 - acc: 0.9267\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.2146 - acc: 0.9271\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.2130 - acc: 0.9268\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.2113 - acc: 0.9272\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.2094 - acc: 0.9284\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.2078 - acc: 0.9289\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.2059 - acc: 0.9297\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.2047 - acc: 0.9293\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.2037 - acc: 0.9292\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.2019 - acc: 0.9305\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.2007 - acc: 0.9305\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.1990 - acc: 0.9317\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.1977 - acc: 0.9325\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.1964 - acc: 0.9318\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.6931 - acc: 0.5171\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5039\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5211\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5131\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5172\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5461\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5224\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5467\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5636\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5525\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5938\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5000\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5000\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5698\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6925 - acc: 0.6327\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6923 - acc: 0.6484\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6920 - acc: 0.6745\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6914 - acc: 0.6799\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6903 - acc: 0.7016\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6882 - acc: 0.7307\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6833 - acc: 0.7596\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6701 - acc: 0.7870\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6309 - acc: 0.8151\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.5492 - acc: 0.8352\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.4752 - acc: 0.8514\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.4291 - acc: 0.8632\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.3967 - acc: 0.8721\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.3711 - acc: 0.8800\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.3499 - acc: 0.8860\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.3316 - acc: 0.8932\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.3161 - acc: 0.8979\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.3031 - acc: 0.9015\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.2921 - acc: 0.9048\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.2825 - acc: 0.9065\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.2736 - acc: 0.9096\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.2659 - acc: 0.9120\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.2588 - acc: 0.9144\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.2523 - acc: 0.9157\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.2469 - acc: 0.9175\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.2421 - acc: 0.9180\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.2379 - acc: 0.9200\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.2342 - acc: 0.9224\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.2310 - acc: 0.9225\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.2280 - acc: 0.9230\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.2257 - acc: 0.9229\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.2230 - acc: 0.9236\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.2207 - acc: 0.9248\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.2189 - acc: 0.9257\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.2171 - acc: 0.9257\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.2149 - acc: 0.9271\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.6932 - acc: 0.5004\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4993\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5006\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4996\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5058\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5121\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4969\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5115\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5107\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5321\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5143\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5029\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5102\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5307\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5333\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6930 - acc: 0.6025\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5698\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5926\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6927 - acc: 0.6046\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6926 - acc: 0.6361\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5929\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6920 - acc: 0.6782\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6913 - acc: 0.7006\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6901 - acc: 0.7199\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6876 - acc: 0.7297\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6820 - acc: 0.7361\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6674 - acc: 0.7545\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6297 - acc: 0.7716\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.5626 - acc: 0.8055\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.4924 - acc: 0.8510\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.4374 - acc: 0.8758\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.3950 - acc: 0.8907\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.3616 - acc: 0.8994\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.3357 - acc: 0.9041\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.3157 - acc: 0.9087\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.2995 - acc: 0.9104\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.2860 - acc: 0.9138\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.2750 - acc: 0.9149\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.2655 - acc: 0.9162\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.2575 - acc: 0.9179\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.2503 - acc: 0.9192\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.2440 - acc: 0.9212\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.2384 - acc: 0.9221\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.2334 - acc: 0.9232\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.2287 - acc: 0.9241\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.2249 - acc: 0.9253\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.2212 - acc: 0.9265\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.2183 - acc: 0.9268\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.2155 - acc: 0.9284\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.2130 - acc: 0.9289\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.6932 - acc: 0.4950\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4950\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5024\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4966\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4983\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4998\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4989\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4979\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4958\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4957\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4974\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4991\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4922\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4918\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4931\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4955\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4966\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5003\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4965\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4999\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4961\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4986\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4999\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4974\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.6931 - acc: 0.5028\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5021\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4969\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4984\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5026\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4943\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5005\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4961\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4966\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4963\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4946\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4986\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4987\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5032\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5075\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4956\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4979\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4995\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5007\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5040\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4982\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5008\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4985\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.6932 - acc: 0.4694\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4715\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4910\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4896\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4854\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4944\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4863\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4968\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4985\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4978\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5040\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4974\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4997\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5024\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5092\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5009\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5032\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5168\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5074\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5194\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5171\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5129\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5256\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5460\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5414\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5589\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5765\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5773\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5761\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6923 - acc: 0.6089\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5836\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6914 - acc: 0.6450\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6905 - acc: 0.6649\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6887 - acc: 0.6926\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6850 - acc: 0.7193\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6765 - acc: 0.7465\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6540 - acc: 0.7708\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6005 - acc: 0.8019\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.5237 - acc: 0.8377\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.4580 - acc: 0.8685\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.4083 - acc: 0.8875\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.3704 - acc: 0.8994\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.3410 - acc: 0.9053\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.3181 - acc: 0.9096\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.2996 - acc: 0.9129\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.2846 - acc: 0.9155\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.2719 - acc: 0.9176\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.2610 - acc: 0.9198\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.2519 - acc: 0.9218\n",
      "Time taken for cross validation: 38.070741115303576\n",
      "(22848, 204)\n",
      "(22848,)\n",
      "Baseline: 84.17% (16.09%)\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=50, batch_size=500, verbose=2)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "start = time.clock()\n",
    "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
    "print(\"Time taken for cross validation:\",time.clock()-start)    \n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.73456659e-01   5.55101056e-02   4.84715062e-02   4.19888867e-02\n",
      "   3.78874266e-02   2.82280892e-02   2.09551744e-02   1.96005725e-02\n",
      "   1.76322375e-02   1.71421847e-02   1.52703071e-02   1.42663146e-02\n",
      "   1.36382321e-02   1.32999108e-02   1.20342950e-02   1.18615563e-02\n",
      "   1.07143064e-02   1.01395230e-02   9.95617230e-03   9.71632972e-03\n",
      "   9.10387854e-03   8.80377792e-03   8.31736640e-03   8.04807303e-03\n",
      "   7.89157503e-03   7.73593288e-03   7.61668543e-03   7.22969670e-03\n",
      "   6.72694539e-03   6.55597772e-03   6.44946626e-03   6.30787934e-03\n",
      "   6.03830460e-03   5.90291388e-03   5.79797205e-03   5.77290698e-03\n",
      "   5.62266612e-03   5.45719509e-03   5.40582922e-03   5.24872596e-03\n",
      "   5.11608632e-03   5.10551916e-03   5.03413438e-03   4.93265198e-03\n",
      "   4.90187087e-03   4.87319594e-03   4.85034801e-03   4.75156768e-03\n",
      "   4.69141216e-03   4.63162002e-03   4.57724491e-03   4.48097997e-03\n",
      "   4.43529094e-03   4.37326709e-03   4.33776161e-03   4.28330573e-03\n",
      "   4.19963671e-03   4.12850088e-03   4.02042818e-03   4.00221368e-03\n",
      "   3.94337055e-03   3.87178043e-03   3.81503699e-03   3.75854984e-03\n",
      "   3.71188556e-03   3.66873352e-03   3.65106786e-03   3.56232933e-03\n",
      "   3.49976193e-03   3.43652611e-03   3.37161850e-03   3.33351890e-03\n",
      "   3.32326047e-03   3.29571670e-03   3.22163760e-03   3.15712006e-03\n",
      "   3.07470779e-03   3.02712016e-03   2.99457881e-03   2.96050339e-03\n",
      "   2.92509020e-03   2.85673732e-03   2.82183812e-03   2.76828319e-03\n",
      "   2.75063477e-03   2.69167691e-03   2.66300243e-03   2.65373707e-03\n",
      "   2.62204796e-03   2.54980522e-03   2.49293889e-03   2.44966053e-03\n",
      "   2.41729357e-03   2.38082758e-03   2.26058661e-03   2.23819558e-03\n",
      "   2.19314477e-03   2.17373743e-03   2.14085616e-03   2.11820663e-03\n",
      "   2.06006745e-03   2.04150448e-03   1.98806678e-03   1.95842361e-03\n",
      "   1.91225445e-03   1.90003705e-03   1.84810031e-03   1.82563192e-03\n",
      "   1.77940725e-03   1.75519813e-03   1.68780510e-03   1.66171448e-03\n",
      "   1.63980889e-03   1.63005160e-03   1.60446107e-03   1.55336846e-03\n",
      "   1.50580513e-03   1.41749545e-03   1.40635436e-03   1.36813473e-03\n",
      "   1.36161060e-03   1.33494271e-03   1.31156686e-03   1.30343544e-03\n",
      "   1.28250948e-03   1.18257340e-03   1.13447473e-03   1.10029013e-03\n",
      "   1.09219912e-03   1.05321372e-03   1.03134124e-03   1.01156609e-03\n",
      "   9.71817175e-04   9.41851911e-04   9.29125806e-04   8.74334059e-04\n",
      "   8.42867263e-04   8.35862163e-04   7.89562985e-04   7.32363112e-04\n",
      "   7.29439602e-04   6.75992826e-04   6.70982318e-04   6.43943940e-04\n",
      "   6.38605510e-04   6.16616682e-04   6.10601950e-04   5.90120686e-04\n",
      "   5.66097343e-04   5.56097780e-04   5.32502737e-04   5.11786938e-04\n",
      "   4.84264819e-04   4.54984630e-04   4.24629003e-04   4.19007954e-04\n",
      "   3.78267152e-04   3.64104924e-04   3.55047061e-04   3.37297768e-04\n",
      "   3.10587799e-04   2.95204167e-04   2.91989114e-04   2.67633430e-04\n",
      "   2.52139149e-04   2.50429525e-04   2.41516110e-04   2.31354445e-04\n",
      "   2.21849115e-04   2.17895111e-04   2.04490109e-04   1.80753422e-04\n",
      "   1.74174690e-04   1.69048877e-04   1.54768337e-04   1.44307568e-04\n",
      "   1.36958901e-04   1.33797872e-04   1.27525369e-04   1.22063717e-04\n",
      "   1.18304096e-04   1.06744410e-04   9.53999728e-05   8.13492379e-05\n",
      "   7.49560817e-05   7.31890189e-05   6.97887776e-05   6.63619867e-05\n",
      "   6.42159228e-05   6.13008001e-05   5.83294432e-05   5.72959030e-05\n",
      "   5.12472730e-05   4.73478000e-05   4.68093260e-05   4.34719254e-05\n",
      "   3.88632503e-05   3.42778451e-05   3.00494662e-05   2.23323487e-05\n",
      "   2.06282779e-05   6.65220447e-06   2.69064082e-06   4.83643908e-07\n",
      "   1.13015291e-07]\n"
     ]
    }
   ],
   "source": [
    "#construct your numpy array of data\n",
    "myData = np.array(data) \n",
    "results = PCA(myData) \n",
    "\n",
    "#this will return an array of variance percentages for each component\n",
    "print(results.fracs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.173456659364\n",
      "1 0.228966764987\n",
      "2 0.277438271175\n",
      "3 0.319427157847\n",
      "4 0.357314584461\n",
      "5 0.385542673669\n",
      "6 0.406497848083\n",
      "7 0.426098420606\n",
      "8 0.443730658071\n",
      "9 0.46087284274\n",
      "10 0.476143149806\n",
      "11 0.490409464367\n",
      "12 0.504047696459\n",
      "13 0.517347607271\n",
      "14 0.529381902222\n",
      "15 0.541243458485\n",
      "16 0.551957764913\n",
      "17 0.562097287946\n",
      "18 0.572053460247\n",
      "19 0.581769789972\n",
      "20 0.590873668517\n",
      "21 0.59967744644\n",
      "22 0.607994812837\n",
      "23 0.616042885867\n",
      "24 0.623934460897\n",
      "25 0.631670393781\n",
      "26 0.639287079213\n",
      "27 0.646516775914\n",
      "28 0.653243721304\n",
      "29 0.659799699021\n",
      "30 0.666249165281\n",
      "31 0.672557044618\n",
      "32 0.678595349217\n",
      "33 0.684498263097\n",
      "34 0.690296235147\n",
      "35 0.696069142128\n",
      "36 0.701691808252\n",
      "37 0.707149003346\n",
      "38 0.712554832569\n",
      "39 0.717803558525\n",
      "40 0.722919644843\n",
      "41 0.728025163998\n",
      "42 0.733059298376\n",
      "43 0.737991950353\n",
      "44 0.742893821224\n",
      "45 0.747767017169\n",
      "46 0.752617365177\n",
      "47 0.757368932853\n",
      "48 0.762060345013\n",
      "49 0.766691965032\n",
      "50 0.771269209941\n",
      "51 0.775750189911\n",
      "52 0.780185480852\n",
      "53 0.78455874794\n",
      "54 0.78889650955\n",
      "55 0.793179815275\n",
      "56 0.797379451986\n",
      "57 0.801507952862\n",
      "58 0.805528381043\n",
      "59 0.809530594726\n",
      "60 0.813473965281\n",
      "61 0.817345745706\n",
      "62 0.821160782693\n",
      "63 0.824919332534\n",
      "64 0.828631218098\n",
      "65 0.832299951618\n",
      "66 0.835951019473\n",
      "67 0.839513348801\n",
      "68 0.843013110727\n",
      "69 0.846449636836\n",
      "70 0.849821255332\n",
      "71 0.853154774227\n",
      "72 0.856478034695\n",
      "73 0.859773751392\n",
      "74 0.862995388994\n",
      "75 0.866152509058\n",
      "76 0.869227216851\n",
      "77 0.872254337007\n",
      "78 0.875248915818\n",
      "79 0.87820941921\n",
      "80 0.881134509412\n",
      "81 0.883991246733\n",
      "82 0.88681308485\n",
      "83 0.889581368042\n",
      "84 0.892332002811\n",
      "85 0.89502367972\n",
      "86 0.897686682152\n",
      "87 0.90034041922\n",
      "88 0.902962467185\n",
      "89 0.905512272409\n",
      "90 0.908005211301\n",
      "91 0.910454871832\n",
      "92 0.912872165398\n",
      "93 0.915252992977\n",
      "94 0.917513579592\n",
      "95 0.919751775172\n",
      "96 0.921944919945\n",
      "97 0.924118657379\n",
      "98 0.92625951354\n",
      "99 0.92837772017\n",
      "100 0.930437787619\n",
      "101 0.932479292096\n",
      "102 0.934467358879\n",
      "103 0.936425782486\n",
      "104 0.938338036933\n",
      "105 0.940238073981\n",
      "106 0.942086174291\n",
      "107 0.943911806214\n",
      "108 0.945691213464\n",
      "109 0.947446411599\n",
      "110 0.949134216701\n",
      "111 0.950795931182\n",
      "112 0.952435740073\n",
      "113 0.954065791674\n",
      "114 0.955670252749\n",
      "115 0.957223621208\n",
      "116 0.95872942634\n",
      "117 0.960146921794\n",
      "118 0.961553276155\n",
      "119 0.962921410885\n",
      "120 0.964283021489\n",
      "121 0.965617964198\n",
      "122 0.966929531054\n",
      "123 0.968232966492\n",
      "124 0.969515475973\n",
      "125 0.970698049377\n",
      "126 0.971832524109\n",
      "127 0.972932814236\n",
      "128 0.974025013358\n",
      "129 0.975078227083\n",
      "130 0.976109568323\n",
      "131 0.977121134408\n",
      "132 0.978092951583\n",
      "133 0.979034803495\n",
      "134 0.979963929301\n",
      "135 0.98083826336\n",
      "136 0.981681130623\n",
      "137 0.982516992786\n",
      "138 0.983306555771\n",
      "139 0.984038918883\n",
      "140 0.984768358485\n",
      "141 0.98544435131\n",
      "142 0.986115333628\n",
      "143 0.986759277568\n",
      "144 0.987397883078\n",
      "145 0.98801449976\n",
      "146 0.98862510171\n",
      "147 0.989215222396\n",
      "148 0.989781319739\n",
      "149 0.990337417518\n",
      "150 0.990869920255\n",
      "151 0.991381707193\n",
      "152 0.991865972012\n",
      "153 0.992320956642\n",
      "154 0.992745585645\n",
      "155 0.993164593599\n",
      "156 0.993542860751\n",
      "157 0.993906965675\n",
      "158 0.994262012736\n",
      "159 0.994599310505\n",
      "160 0.994909898304\n",
      "161 0.995205102471\n",
      "162 0.995497091585\n",
      "163 0.995764725016\n",
      "164 0.996016864165\n",
      "165 0.99626729369\n",
      "166 0.9965088098\n",
      "167 0.996740164245\n",
      "168 0.99696201336\n",
      "169 0.997179908471\n",
      "170 0.99738439858\n",
      "171 0.997565152002\n",
      "172 0.997739326692\n",
      "173 0.997908375569\n",
      "174 0.998063143906\n",
      "175 0.998207451474\n",
      "176 0.998344410375\n",
      "177 0.998478208247\n",
      "178 0.998605733616\n",
      "179 0.998727797333\n",
      "180 0.998846101429\n",
      "181 0.998952845838\n",
      "182 0.999048245811\n",
      "183 0.999129595049\n",
      "184 0.999204551131\n",
      "185 0.99927774015\n",
      "186 0.999347528927\n",
      "187 0.999413890914\n",
      "188 0.999478106837\n",
      "189 0.999539407637\n",
      "190 0.99959773708\n",
      "191 0.999655032983\n",
      "192 0.999706280256\n",
      "193 0.999753628056\n",
      "194 0.999800437382\n",
      "195 0.999843909307\n",
      "196 0.999882772558\n",
      "197 0.999917050403\n",
      "198 0.999947099869\n",
      "199 0.999969432218\n",
      "200 0.999990060496\n",
      "201 0.9999967127\n",
      "202 0.999999403341\n",
      "203 0.999999886985\n",
      "204 1.0\n"
     ]
    }
   ],
   "source": [
    "temp=0\n",
    "for i in range(205):\n",
    "    temp=temp+results.fracs[i]\n",
    "    print(i,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  17.4256869    22.87648244   27.74722925   31.93755196   35.74216105\n",
      "   38.51447212   40.60327686   42.57018116   44.34038487   46.06255739\n",
      "   47.5903869    49.0240104    50.38927689   51.72523633   52.92346646\n",
      "   54.10405245   55.1798051    56.19611237   57.1944691    58.17077628\n",
      "   59.08326767   59.96791836   60.80192471   61.61036072   62.40338476\n",
      "   63.18046684   63.94575254   64.67224115   65.34634095   65.99693619\n",
      "   66.64461476   67.27849066   67.88491127   68.47741713   69.05826756\n",
      "   69.63351135   70.19816945   70.74508204   71.28798549   71.81379346\n",
      "   72.32773039   72.8407574    73.34657507   73.84196624   74.33433454\n",
      "   74.82403876   75.31133367   75.78859566   76.25966499   76.7249157\n",
      "   77.18380038   77.63405984   78.07974973   78.51917416   78.95472378\n",
      "   79.38497369   79.80585414   80.22042305   80.62395107   81.02597962\n",
      "   81.42080621   81.80938775   82.19272479   82.57039413   82.93992872\n",
      "   83.30689931   83.67341553   84.0313946    84.38276865   84.72789642\n",
      "   85.06671063   85.40169355   85.73458509   86.06573325   86.38904345\n",
      "   86.70630236   87.01527822   87.319076     87.61996436   87.91733609\n",
      "   88.21105639   88.49813034   88.78158258   89.05936257   89.33554929\n",
      "   89.60602174   89.87359416   90.14026861   90.40375813   90.65980648\n",
      "   90.90970116   91.1550507    91.39781631   91.6370616    91.86415252\n",
      "   92.08674281   92.30712994   92.52518573   92.74018248   92.95282668\n",
      "   93.15921767   93.36421657   93.56392823   93.75905335   93.95016362\n",
      "   94.13703427   94.3218301    94.50334201   94.68117169   94.85571707\n",
      "   95.02442885   95.19017064   95.35445438   95.51633615   95.67243628\n",
      "   95.82423925   95.96899404   96.11104801   96.25197966   96.38944985\n",
      "   96.52451042   96.65859403   96.78958811   96.91892353   97.03955352\n",
      "   97.15419972   97.26777494   97.37784115   97.48368134   97.58841361\n",
      "   97.6911496    97.78898418   97.88364588   97.97724668   98.06622992\n",
      "   98.15269803   98.23717471   98.31723865   98.39258968   98.46590449\n",
      "   98.5338555    98.60157785   98.66646357   98.73114569   98.79327667\n",
      "   98.85471342   98.91403536   98.97101691   99.02694388   99.08065774\n",
      "   99.13211226   99.18092294   99.22709797   99.26976914   99.31187772\n",
      "   99.34989845   99.38677859   99.42249744   99.45652074   99.48774363\n",
      "   99.51746327   99.54681206   99.57371819   99.59905802   99.62423453\n",
      "   99.64854851   99.67199514   99.69434179   99.71628715   99.73687102\n",
      "   99.75510041   99.77260799   99.78963711   99.80519084   99.81969306\n",
      "   99.83345862   99.84690432   99.85972083   99.87205123   99.8839493\n",
      "   99.89469359   99.904287     99.91246452   99.91999975   99.92735716\n",
      "   99.93437039   99.94105185   99.94751917   99.95368179   99.95954375\n",
      "   99.96530151   99.97046628   99.97522575   99.97993114   99.98430099\n",
      "   99.98820641   99.99165711   99.99467847   99.99692275   99.99899724\n",
      "   99.99966755   99.99993835   99.99998864  100.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x3b88c0b2b0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBNz/B6x+ZjQffl01AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3b9f7b8278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=204)\n",
    "X=scale(X)\n",
    "reduced_X = pca.fit_transform(X)\n",
    "var = pca.explained_variance_ratio_\n",
    "var1 = np.cumsum(pca.explained_variance_ratio_*100)\n",
    "print(var1)\n",
    "plt.plot(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22848, 72)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=72)\n",
    "pca.fit(X)\n",
    "X1=pca.fit_transform(X)\n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train using gini: 0.597561600903191\n",
      "Time taken to train using entropy: 0.9700022316426384\n",
      "(15993, 72)\n",
      "(15993,)\n",
      "Results Using Gini Index:\n",
      "Time taken to test using gini: 0.0026794360244366544\n",
      "Confusion Matrix:\n",
      " [[2627  795]\n",
      " [ 711 2722]]\n",
      "Accuracy :\n",
      " 78.0306345733\n",
      "Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.79      0.77      0.78      3422\n",
      "        1.0       0.77      0.79      0.78      3433\n",
      "\n",
      "avg / total       0.78      0.78      0.78      6855\n",
      "\n",
      "Results Using Entropy:\n",
      "Time taken to test using entropy: 0.002551006705175496\n",
      "Confusion Matrix:\n",
      " [[2440  982]\n",
      " [ 517 2916]]\n",
      "Accuracy :\n",
      " 78.1327498177\n",
      "Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.83      0.71      0.77      3422\n",
      "        1.0       0.75      0.85      0.80      3433\n",
      "\n",
      "avg / total       0.79      0.78      0.78      6855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spliting the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size = 0.3, random_state = 100)\n",
    "\n",
    "# Performing training\n",
    "start = time.clock()\n",
    "clf_gini.fit(X_train, y_train)\n",
    "print(\"Time taken to train using gini:\",time.clock()-start)    \n",
    "\n",
    "# Performing training\n",
    "start = time.clock()\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "print(\"Time taken to train using entropy:\",time.clock()-start)    \n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)    \n",
    "\n",
    "# Operational Phase\n",
    "\n",
    "print(\"Results Using Gini Index:\")     \n",
    "# Prediction using gini\n",
    "start = time.clock()\n",
    "y_pred_gini = clf_gini.predict(X_test)\n",
    "print(\"Time taken to test using gini:\",time.clock()-start)    \n",
    "cal_accuracy(y_test, y_pred_gini)\n",
    "     \n",
    "print(\"Results Using Entropy:\")\n",
    "# Prediction using entropy\n",
    "start = time.clock()\n",
    "y_pred_entropy = clf_entropy.predict(X_test)\n",
    "print(\"Time taken to test using entropy:\",time.clock()-start)    \n",
    "cal_accuracy(y_test, y_pred_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15993, 72)\n",
      "(15993,)\n",
      "Time taken to train using svm: 73.33341569738343\n",
      "Time taken to test using svm: 2.2820014854828514\n",
      "Confusion Matrix:\n",
      " [[3059  363]\n",
      " [ 317 3116]]\n",
      "Accuracy :\n",
      " 90.0802334063\n",
      "Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.91      0.89      0.90      3422\n",
      "        1.0       0.90      0.91      0.90      3433\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "start = time.clock()\n",
    "svm_model_linear.fit(X_train, y_train)\n",
    "print(\"Time taken to train using svm:\",time.clock()-start)    \n",
    "start = time.clock()\n",
    "svm_predictions = svm_model_linear.predict(X_test)\n",
    "print(\"Time taken to test using svm:\",time.clock()-start)    \n",
    "cal_accuracy(y_test, svm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 1s - loss: 0.6932 - acc: 0.4990\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4885\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4850\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4934\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4985\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4967\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4986\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4980\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4913\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4991\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4966\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4987\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4986\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4982\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4978\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4961\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5001\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4981\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4977\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4973\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4939\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4997\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4975\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4960\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4960\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4949\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4976\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4969\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4967\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4988\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4962\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4968\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4980\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4966\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4985\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4963\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4972\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4944\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4939\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4953\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.6931 - acc: 0.5053\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5020\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5024\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5020\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5007\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5093\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5063\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5066\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5182\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5020\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5228\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5042\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5146\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5180\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5250\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5109\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5110\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5335\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5112\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5179\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5188\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5073\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5579\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5489\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5474\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5443\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5434\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5585\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5254\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5840\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5759\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5849\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5697\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5750\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5484\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5940\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6925 - acc: 0.6182\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5999\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6922 - acc: 0.6241\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6919 - acc: 0.6051\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6917 - acc: 0.6189\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6913 - acc: 0.6603\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6907 - acc: 0.6731\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6900 - acc: 0.6183\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6889 - acc: 0.6865\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6872 - acc: 0.7219\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6844 - acc: 0.7075\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6798 - acc: 0.7275\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.6932 - acc: 0.4885\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4990\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4980\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4999\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4959\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4970\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4906\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4963\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4961\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4984\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5028\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4953\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5041\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4971\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5011\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5005\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5003\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5052\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5047\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5007\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5055\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5036\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5108\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5044\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5003\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5079\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5003\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5013\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5034\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5207\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5221\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5227\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5117\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5310\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5122\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5258\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5290\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5103\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5019\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5101\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5439\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5355\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5418\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5317\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5699\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5652\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5207\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5917\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6927 - acc: 0.6022\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5530\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.6932 - acc: 0.4993\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4954\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5003\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4994\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5003\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5009\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4996\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5006\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5016\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4946\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4956\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4998\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5007\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4958\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4934\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4938\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4976\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5031\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4992\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4957\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5002\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4971\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5036\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4989\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4992\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.6931 - acc: 0.5096\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5057\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5010\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4974\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5092\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5061\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5103\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5079\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5016\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5044\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5219\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5079\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5076\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5384\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5408\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5190\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5381\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5097\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5063\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5521\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5469\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5115\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5480\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5162\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.6932 - acc: 0.4736\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4752\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4905\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4904\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4843\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4898\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4839\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4933\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4969\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4982\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4990\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4927\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4897\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4911\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4984\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4917\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4978\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4965\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4995\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4950\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4999\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5001\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5013\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4945\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4938\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5017\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5003\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4999\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4994\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4996\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4987\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4977\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4995\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4997\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5003\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5010\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5065\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5024\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5027\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5022\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5024\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5058\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5008\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5106\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5088\n",
      "Time taken for cross validation: 36.444489478806645\n",
      "(22848, 72)\n",
      "(22848,)\n",
      "Baseline: 58.52% (9.42%)\n"
     ]
    }
   ],
   "source": [
    "def create_baseline():\n",
    " # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2, input_dim=72, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(2, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    sgd = SGD(lr=0.01, momentum=0.8, decay=0.0, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=50, batch_size=500, verbose=2)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "start = time.clock()\n",
    "results = cross_val_score(pipeline, X1, y, cv=kfold)\n",
    "print(\"Time taken for cross validation:\",time.clock()-start)    \n",
    "print(X1.shape)\n",
    "print(y.shape)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
